{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "038d215e",
   "metadata": {},
   "source": [
    "# Этап 2: Обучение и Оценка Модели Обнаружения Объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91778f89",
   "metadata": {},
   "source": [
    "На этом этапе проекта мы переходим к обучению нейронной сети для обнаружения сноубордистов на подготовленном датасете. \n",
    "\n",
    "**Цель:** получить высокопроизводительную и точную модель-детектор, способную эффективно локализовать объекты класса 'snowboarder' на изображениях и видео.\n",
    "\n",
    "**Примечание для читателя:**\n",
    "Данный ноутбук демонстрирует процесс обучения и оценки моделей. Все конфигурационные параметры и логирование экспериментов могут быть дополнительно настроены и отслежены с помощью инструментов, таких как Weights & Biases, для более глубокого анализа.\n",
    "\n",
    "---\n",
    "\n",
    "**Ключевые особенности этого этапа:**\n",
    "\n",
    "* **Централизованное управление параметрами:** Все ключевые конфигурационные параметры (такие как тип модели, количество эпох, размер изображения, использование W&B и другие) определяются в одном словаре `training_config`, что упрощает модификацию и контроль над экспериментами.\n",
    "* **Интеграция Weights & Biases (W&B):** Весь процесс обучения и оценки модели полностью интегрирован с W&B. Это позволяет в реальном времени отслеживать метрики (потери, точность, полнота), визуализировать графики (PR-кривые, матрицы ошибок), фиксировать все параметры запуска и артефакты (обученные модели), а также сравнивать результаты различных экспериментов в едином облачном интерфейсе.\n",
    "* **Динамическое именование запусков:** Локальные директории для сохранения результатов обучения и тестирования, а также соответствующие раны в W&B, автоматически получают уникальные, последовательные имена. Это предотвращает перезапись данных и упрощает навигацию по множеству экспериментов.\n",
    "* **Упорядоченная структура выходных данных:** Все сгенерированные артефакты (веса моделей, графики обучения, логи, результаты валидации) сохраняются в четко определенной иерархии в папке `runs/` (например, `runs/detect/`, `runs/wandb/`), обеспечивая чистоту проекта и легкий доступ к результатам.\n",
    "\n",
    "В первой части мы сфокусируемся на обучении **YOLOv8** как основной архитектуры, благодаря её балансу между скоростью и точностью, что критически важно для дальнейшей интеграции в систему слежения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9423301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых системных и стандартных библиотек\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# Добавление корневой директории проекта в sys.path\n",
    "# Это позволяет импортировать вспомогательные модули из папок, расположенных на одном уровне с 'notebooks/' (например, из 'scripts/')\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Импорт основной библиотеки для работы с моделью и отображением\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Импорт пользовательских вспомогательных утилит\n",
    "from scripts.visualization_utils import display_and_log_multiple_image_artifacts # Для визуализации и логирования изображений\n",
    "from scripts.utils import get_next_run_name, check_yolo_dataset_paths # Утилиты для генерации имен запусков и проверки путей датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2da005",
   "metadata": {},
   "source": [
    "## 1. Обучение YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee9429f",
   "metadata": {},
   "source": [
    "Будем использовать фреймворк Ultralytics YOLOv8 для обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059ae57",
   "metadata": {},
   "source": [
    "### 1.1. Конфигурация Датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694c9d37",
   "metadata": {},
   "source": [
    "Перед началом обучения необходимо убедиться, что файл конфигурации `dataset.yaml` корректно указывает на подготовленные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c42738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к файлу dataset.yaml\n",
    "dataset_yaml_path = '../resources/dataset.yaml'\n",
    "\n",
    "# Проверяем пути в dataset.yaml\n",
    "print(\"Проверка файла dataset.yaml и доступности указанных в нем путей:\")\n",
    "paths_are_ok = check_yolo_dataset_paths(dataset_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c8322b",
   "metadata": {},
   "source": [
    "### 1.2. Загрузка предобученной модели и обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef9c7c9",
   "metadata": {},
   "source": [
    "Мы начнем с загрузки предобученной модели YOLOv8 (`yolov8n.pt` — 'n' означает 'nano', самую маленькую и быструю версию). Использование предобученной модели на большом датасете (например, COCO) позволяет нам воспользоваться уже выученными признаками и значительно ускорить процесс обучения на наших специфических данных (transfer learning).\n",
    "\n",
    "**Параметры обучения:**\n",
    "* **`data`:** Путь к файлу `dataset.yaml`.\n",
    "* **`epochs`:** Количество эпох обучения. Для начала, 50-100 эпох будет достаточно для демонстрации. Если модель будет недообучена, можно увеличить.\n",
    "* **`imgsz`:** Размер изображения, до которого оно будет масштабироваться перед подачей в модель. 640 — стандартное значение.\n",
    "* **`batch`:** Размер батча. Рекомендуется подбирать в зависимости от доступной GPU памяти. `-1` для автоматического подбора.\n",
    "* **`name`:** Название эксперимента. Результаты обучения будут сохранены в `runs/detect/<name>/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6399f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Загрузка предобученной модели и обучение ---\n",
    "\n",
    "# Конфигурация параметров обучения и W&B\n",
    "training_config = {\n",
    "    \"model_name_prefix\": 'yolo11n',              # Префикс для имени модели\n",
    "    \"epochs\": 100,                               # Количество эпох\n",
    "    \"imgsz\": 640,                                # Размер изображения\n",
    "    \"batch_size\": -1,                            # Размер батча (-1 для автоподбора)\n",
    "    \"patience\": 50,                              # Количество эпох без улучшения на val loss\n",
    "    \"resume\": False,                             # Продолжить с контрольной точки\n",
    "    \"project_name\": \"snowboard-tracking\",        # Имя проекта в Weights & Biases\n",
    "    \"run_base_prefix\": \"snowboarder_detection\",  # Базовый префикс для нумерации запусков\n",
    "    \"use_wandb\": True,                           # Использовать Weights & Biases для логирования\n",
    "    \"device\": None                               # Или 0, 'cpu'\n",
    "}\n",
    "\n",
    "print(\"Загрузка предобученной модели и обучение\")\n",
    "\n",
    "# Определяем имя для текущего тренировочного запуска\n",
    "current_train_run_name = get_next_run_name(\n",
    "    f\"{training_config['model_name_prefix']}_{training_config['run_base_prefix']}\"\n",
    ")\n",
    "\n",
    "# Инициализация W&B run (опционально)\n",
    "if training_config['use_wandb']:\n",
    "    print(f\"Инициализация Weights & Biases для запуска '{current_train_run_name}'...\")\n",
    "    wandb.init(\n",
    "        project=training_config['project_name'],\n",
    "        name=current_train_run_name,\n",
    "        config=training_config, # Логируем все параметры конфигурации\n",
    "        dir='../runs'\n",
    "    )\n",
    "else:\n",
    "    print(\"Логирование в Weights & Biases отключено.\")\n",
    "    os.environ[\"WANDB_MODE\"] = \"dryrun\" # Это заставит W&B не логировать, но не вызовет ошибок, если wandb.init() не был вызван.\n",
    "\n",
    "# Загрузка модели\n",
    "model = YOLO(f'{training_config[\"model_name_prefix\"]}.pt') \n",
    "print(f\"Модель YOLO11 ({training_config['model_name_prefix']}.pt) загружена.\")\n",
    "\n",
    "# Обучение модели\n",
    "print(f\"\\nНачинаем обучение модели YOLO11. Результаты будут сохранены в {os.path.join('runs', 'detect', current_train_run_name)}/\")\n",
    "\n",
    "start_time = time.time()\n",
    "results = model.train(\n",
    "    data=dataset_yaml_path,               # Путь к файлу конфигурации датасета\n",
    "    epochs=training_config['epochs'],     # Количество эпох\n",
    "    imgsz=training_config['imgsz'],       # Размер изображения\n",
    "    batch=training_config['batch_size'],  # Размер батча (-1 для автоподбора)\n",
    "    name=current_train_run_name,          # Название эксперимента (для папки runs/detect/)\n",
    "    project='../runs/detect',             # Подпапка внутри 'runs/' (т.е. runs/detect/...)\n",
    "    device=training_config['device'],     # Убедитесь, что GPU доступен, иначе оставьте пустым для CPU или 'cpu'\n",
    "    patience=training_config['patience'], # Количество эпох без улучшения на val loss\n",
    "    resume=training_config['resume'],     # Продолжить обучение с последней контрольной точки\n",
    "    val=True,                             # Проводить валидацию на каждой эпохе\n",
    "    # callbacks=True                      # Необязательно, если wandb.init() был вызван, YOLOv8 обычно сам подключит W&B колбэки.\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "training_duration_seconds = end_time - start_time\n",
    "training_duration_minutes = training_duration_seconds / 60\n",
    "\n",
    "print(\"\\nОбучение YOLO11 завершено.\")\n",
    "\n",
    "# Сохраняем имя папки с обучением для дальнейшего использования (например, для тестирования)\n",
    "latest_train_run_dir = model.trainer.save_dir\n",
    "print(f\"Результаты обучения сохранены в: {latest_train_run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a60dfbb",
   "metadata": {},
   "source": [
    "### 1.3. Анализ результатов обучения YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f02de",
   "metadata": {},
   "source": [
    "Обучение модели YOLOv8n завершилось успешно, показав отличные метрики на валидационном наборе.\n",
    "\n",
    "**Ключевые показатели после 100 эпох:**\n",
    "\n",
    "* **Итоговая оценка на валидационном наборе (по модели `best.pt`):**\n",
    "    * `Precision (P)`: **0.969** - Из всех предсказаний, почти 97% были корректными.\n",
    "    * `Recall (R)`: **1** - Модель обнаружила абсолютно всех (или почти всех) сноубордистов на валидационных изображениях.\n",
    "    * `mAP50`: **0.992** - Практически идеальная средняя точность при пороге IoU 0.5.\n",
    "    * `mAP50-95`: **0.868** - Очень высокий показатель средней точности по диапазону порогов IoU, свидетельствующий о превосходном качестве предсказанных ограничивающих рамок.\n",
    "\n",
    "* **Скорость инференса на GPU (NVIDIA GeForce RTX 2060)**:\n",
    "    * **1.1** мс на инференс + 1.5 мс на постобработку = 2.6 мс общее время на изображение\n",
    "    * Это составляет примерно ~**385** кадров в секунду (FPS) для полного пайплайна\n",
    "    * Чистый инференс: ~**909** FPS (только нейросеть без постобработки)\n",
    "\n",
    "\n",
    "* **Характеристики модели:**\n",
    "    * **3,005,843** параметра - компактная архитектура\n",
    "    * **8.1** GFLOPs - вычислительная сложность\n",
    "    * **6.2** MB размер модели - идеально для мобильных устройств\n",
    "\n",
    "Такие результаты свидетельствуют о высоком качестве подготовленного датасета и эффективности выбранной архитектуры YOLOv8 для данной задачи. Модель успешно выучила признаки сноубордистов и демонстрирует отличную способность к их обнаружению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91077d",
   "metadata": {},
   "source": [
    "### 1.4. Визуализация результатов обучения YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e59f15",
   "metadata": {},
   "source": [
    "Ultralytics автоматически генерирует полезные графики во время обучения, которые позволяют отслеживать прогресс модели и выявлять потенциальные проблемы (например, переобучение или недообучение). Эти графики находятся в папке, где были сохранены результаты обучения (`yolov8n_snowboarder_v1`).\n",
    "\n",
    "Мы отобразим ключевые графики:\n",
    "* `results.png`: Сводный график потерь и метрик (mAP, Precision, Recall) по эпохам.\n",
    "* `PR_curve.png`: Precision-Recall кривая.\n",
    "* `confusion_matrix.png`: Матрица ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к папке с результатами обучения\n",
    "train_results_dir = model.trainer.save_dir\n",
    "\n",
    "print(f\"\\n 1.4 Визуализация результатов обучения\")\n",
    "print(f\"Графики обучения сохранены в: {train_results_dir}\")\n",
    "\n",
    "# Файлы графиков, которые Ultralytics генерирует в директории обучения\n",
    "training_plot_files = [\n",
    "    'results.png',\n",
    "    'BoxPR_curve.png',\n",
    "    'confusion_matrix.png'\n",
    "]\n",
    "\n",
    "# Словарь для передачи индивидуальной ширины, если нужно\n",
    "training_plot_widths = {\n",
    "    'BoxPR_curve.png': 600,\n",
    "    'confusion_matrix.png': 600\n",
    "}\n",
    "\n",
    "# Используем display_and_log_multiple_image_artifacts только для отображения в ноутбуке\n",
    "# W&B уже логирует эти файлы автоматически.\n",
    "display_and_log_multiple_image_artifacts(\n",
    "    base_dir=train_results_dir,\n",
    "    image_filenames=training_plot_files,\n",
    "    prefix_title=\"График обучения\",\n",
    "    wandb_artifacts_dict=None,\n",
    "    wandb_key_prefix=None,\n",
    "    widths=training_plot_widths\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0bd3f",
   "metadata": {},
   "source": [
    "## 2. Тестирование модели на независимой тестовой выборке\n",
    "\n",
    "После завершения обучения и получения финальных весов модели, крайне важно провести её объективную оценку на **независимом тестовом наборе данных**. Этот набор состоит из изображений, которые модель не видела ни на этапе обучения, ни на этапе валидации. Такая оценка дает наиболее точное представление об обобщающей способности модели и её производительности в реальных условиях.\n",
    "\n",
    "Мы используем веса `best.pt`, полученные в результате обучения, для проведения валидации на тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2. Оценка Модели на Независимом Тестовом Наборе\")\n",
    "\n",
    "# Загрузка лучшей обученной модели\n",
    "best_model_path = os.path.join(latest_train_run_dir, 'weights', 'best.pt')\n",
    "\n",
    "print(f\"Загружаем лучшую модель из: {best_model_path}\")\n",
    "loaded_model = YOLO(best_model_path)\n",
    "\n",
    "# Определяем имя для текущего тестового запуска\n",
    "test_run_base_name = f\"test_{training_config['model_name_prefix']}_{training_config['run_base_prefix']}\"\n",
    "current_test_run_name = get_next_run_name(test_run_base_name)\n",
    "\n",
    "# Проведение валидации на тестовом наборе\n",
    "print(\"\\nЗапускаем валидацию на тестовом наборе...\")\n",
    "test_results = loaded_model.val(\n",
    "    data=dataset_yaml_path,          # Используем тот же dataset.yaml\n",
    "    split='test',                    # Указываем, что валидацию нужно провести на тестовом наборе\n",
    "    imgsz=training_config['imgsz'],  # Используем imgsz из конфига обучения\n",
    "    conf=0.25,                       # Порог уверенности для детекции (можно настроить)\n",
    "    iou=0.7,                         # Порог IoU для NMS (можно настроить)\n",
    "    plots=True,                      # Генерировать графики результатов\n",
    "    name=current_test_run_name,      # Динамическое имя для тестового запуска\n",
    "    project='../runs/detect'         # Подпапка внутри 'runs/' (т.е. runs/detect/...)\n",
    ")\n",
    "\n",
    "print(\"\\nВалидация на тестовом наборе завершена.\")\n",
    "\n",
    "# Вывод основных метрик на тестовом наборе\n",
    "print(\"\\nМетрики на тестовом наборе:\")\n",
    "final_p = test_results.box.p.item() if test_results.box.p is not None else float('nan')\n",
    "final_r = test_results.box.r.item() if test_results.box.r is not None else float('nan')\n",
    "final_map50 = test_results.box.map50.item() if test_results.box.map50 is not None else float('nan')\n",
    "final_map = test_results.box.map.item() if test_results.box.map is not None else float('nan')\n",
    "\n",
    "print(f\"   Precision (P): {final_p:.3f}\")\n",
    "print(f\"   Recall (R): {final_r:.3f}\")\n",
    "print(f\"   mAP50: {final_map50:.3f}\")\n",
    "print(f\"   mAP50-95: {final_map:.3f}\")\n",
    "\n",
    "# Логирование финальных метрик тестового набора в W&B (если W&B был активен)\n",
    "if training_config['use_wandb']:\n",
    "    wandb.log({\n",
    "        \"test/precision\": final_p,\n",
    "        \"test/recall\": final_r,\n",
    "        \"test/mAP50\": final_map50,\n",
    "        \"test/mAP50-95\": final_map\n",
    "    })\n",
    "    # Логирование времени обучения\n",
    "    if 'training_duration_seconds' in locals():\n",
    "        wandb.log({\n",
    "            \"training_duration_seconds\": training_duration_seconds,\n",
    "            \"training_duration_minutes\": training_duration_minutes\n",
    "        })\n",
    "\n",
    "# Путь к сгенерированным графикам из теста\n",
    "plots_test_dir = test_results.save_dir\n",
    "\n",
    "print(f\"\\nПримеры предсказаний и графики оценки на тестовом наборе сохранены в: {plots_test_dir}\")\n",
    "\n",
    "# Файлы графиков для тестового набора\n",
    "test_plot_files = [\n",
    "    'val_batch0_pred.jpg', # Пример предсказаний на первом батче валидации\n",
    "    'BoxPR_curve.png',     # PR-кривая для теста\n",
    "    'confusion_matrix.png' # Матрица ошибок для теста, если нужна\n",
    "]\n",
    "\n",
    "display_and_log_multiple_image_artifacts(\n",
    "    base_dir=plots_test_dir,\n",
    "    image_filenames=test_plot_files,\n",
    "    prefix_title=\"Тестовый результат\",\n",
    "    wandb_artifacts_dict=None, # Не передаем словарь для W&B артефактов\n",
    "    wandb_key_prefix=None\n",
    ")\n",
    "\n",
    "# Завершаем W&B run в самом конце эксперимента\n",
    "if training_config['use_wandb']:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761b879",
   "metadata": {},
   "source": [
    "### 2.2. Анализ Результатов на Тестовой Выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83517f4d",
   "metadata": {},
   "source": [
    "Результаты валидации на независимой тестовой выборке подтверждают высокую обобщающую способность обученной модели YOLOv8n.\n",
    "\n",
    "**Ключевые показатели на тестовом наборе (63 изображения):**\n",
    "\n",
    "* `Precision (P)`: **0.984** - Модель демонстрирует крайне низкое количество ложных срабатываний.\n",
    "* `Recall (R)`: **1.000** - Модель успешно обнаружила всех сноубордистов, присутствующих в тестовом наборе. Это критически важно для задачи трекинга, так как пропущенные детекции значительно ухудшают качество трекинга.\n",
    "* `mAP50`: **0.994** - Практически идеальная средняя точность при пороге IoU 0.5, что говорит о высочайшем качестве локализации объектов.\n",
    "* `mAP50-95`: **0.842** - Очень сильный показатель, указывающий на хорошую точность рамок даже при строгих порогах IoU.\n",
    "\n",
    "Эти метрики являются **отличным фундаментом** для построения надежной системы слежения за сноубордистом. Модель-детектор готова к интеграции с алгоритмами трекинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ee760",
   "metadata": {},
   "source": [
    "## **3 Завершение этапа и выводы**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c5fa05",
   "metadata": {},
   "source": [
    "Обучение и тщательная оценка модели YOLOv8 для обнаружения сноубордистов успешно завершены. Модель продемонстрировала высокую производительность как на валидационной, так и на полностью независимой тестовой выборке, подтверждая свою способность эффективно обобщать и детектировать объекты на ранее невиданных данных.\n",
    "\n",
    "**Ключевые показатели производительности обученной модели YOLOv8n:**\n",
    "\n",
    "**На независимом тестовом наборе (63 изображения, 41 экземпляр сноубордиста):**\n",
    "\n",
    "* `Precision (P)`: **0.984** - Модель демонстрирует крайне низкое количество ложных срабатываний, что означает высокую надежность детекций.\n",
    "* `Recall (R)`: **1.000** - Модель успешно обнаружила **всех** сноубордистов, присутствующих в тестовом наборе. Это критически важно для задачи трекинга, так как пропущенные детекции значительно ухудшают качество отслеживания.\n",
    "* `mAP50`: **0.995** - Практически идеальная средняя точность при пороге Intersection Over Union (IoU) 0.5. Это говорит о высочайшем качестве как детекции, так и локализации ограничивающих рамок.\n",
    "* `mAP50-95`: **0.842** - Очень сильный показатель, указывающий на хорошую точность рамок даже при более строгих порогах IoU (от 0.5 до 0.95).\n",
    "\n",
    "**Характеристики и скорость инференса обученной модели (на NVIDIA GeForce RTX 2060):**\n",
    "\n",
    "* **Скорость инференса:**\n",
    "    * Чистый инференс (только нейросеть): около **1.1 мс** на изображение.\n",
    "    * Полный пайплайн (инференс + постобработка): около **2.6 мс** на изображение (1.1 мс инференс + 1.5 мс постобработка).\n",
    "    * Это соответствует примерно **~385 кадрам в секунду (FPS)** для полного пайплайна, что идеально подходит для задач отслеживания в реальном времени.\n",
    "    * _Примечание: Во время тестовой валидации скорость инференса могла быть снижена за счет особенностей обработки тестового батча и дополнительного логирования. При работе модели в реальном приложении ожидается стабильная скорость на уровне 1-2 мс на изображение._\n",
    "\n",
    "* **Архитектурные особенности модели YOLOv8n:**\n",
    "    * **3,005,843** параметра - указывает на компактную и легковесную архитектуру, что снижает требования к памяти и вычислительным ресурсам.\n",
    "    * **8.1 GFLOPs** - вычислительная сложность модели. Относительно низкое значение подтверждает ее эффективность.\n",
    "    * **6.2 MB** размер файла модели - чрезвычайно малый размер, что делает ее идеальной для развертывания на устройствах с ограниченными ресурсами, включая мобильные платформы и встраиваемые системы.\n",
    "\n",
    "Все ключевые метрики обучения и оценки, а также параметры эксперимента и визуализации, были автоматически залогированы в Weights & Biases. Это обеспечивает полную прозрачность и воспроизводимость каждого запуска, позволяя легко сравнивать результаты и отслеживать прогресс проекта. Локальные артефакты (обученные веса модели, графики обучения и валидации) аккуратно сохранены в структурированной директории `runs/detect/`.\n",
    "\n",
    "Эта высокоэффективная и тщательно протестированная модель обнаружения объектов теперь является прочной основой для следующего этапа проекта — реализации системы отслеживания и центрирования сноубордиста в видеопотоке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f668d644",
   "metadata": {},
   "source": [
    "### Сравнительный анализ производительности моделей YOLOv8n, YOLOv8s и YOLO11n\n",
    "\n",
    "Для принятия обоснованного решения о выборе оптимальной модели для задачи отслеживания в реальном времени, был проведен сравнительный анализ трех версий YOLO: `yolov8n` (nano), `yolov8s` (small) и `yolo11n` (nano).\n",
    "\n",
    "| Метрика / Характеристика | YOLOv8n (Nano) | YOLOv8s (Small) | YOLO11n (Nano) | Комментарий                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
    "| :---------------------- | :------------- | :-------------- | :------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Параметры (общие)** | 3.0M           | 11.1M           | **2.6M** | `yolo11n` является самой компактной моделью с наименьшим количеством параметров.                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| **GFLOPs (общие)** | 8.1 GFLOPs     | 28.4 GFLOPs     | **6.3 GFLOPs** | `yolo11n` является самой легкой с точки зрения вычислительной сложности, что способствует высокой скорости инференса.                                                                                                                                                                                                                                                                                                                                                         |\n",
    "| **Время обучения (100 эпох)** | ~5 минут      | ~7 минут (0.114 часа) | **~4.26 минут (0.071 часа)** | `yolo11n` обучается быстрее всех, демонстрируя высокую эффективность.                                                                                                                                                                                                                                                                                                                                       |\n",
    "| **mAP50 (Тест)** | **0.995** | 0.994           | 0.994          | Все модели демонстрируют исключительно высокие и практически идентичные mAP50, что говорит о высоком качестве детекции при стандартном пороге IoU.                                                                                                                                                                                                                                                                                                    |\n",
    "| **mAP50-95 (Тест)** | 0.842          | 0.834           | **0.859** | `yolo11n` достигает наивысшего `mAP50-95`, что указывает на лучшую точность локализации ограничивающих рамок даже при строгих порогах IoU. Это критически важный показатель качества модели.                                                                                                                                                            |\n",
    "| **Precision (P) (Тест)** | **0.984** | 0.982           | 0.974          | Все модели имеют очень высокую точность (минимум ложных срабатываний). `yolo11n` лишь незначительно уступает.                                                                                                                                                                                                                                                                                                                                                                                   |\n",
    "| **Recall (R) (Тест)** | **1.000** | 0.984           | **1.000** | `yolo11n` и `yolov8n` достигают идеального Recall, не пропуская ни одного объекта в тестовом наборе, что является ключевым требованием для надежного трекинга.                                                                                                                                                                                                                                                                                              |\n",
    "| **Скорость инференса (чистый / полный пайплайн, мс/изображение)** | ~1.1 / ~2.6 | ~8.4 / ~11.9 | **~1.1 / ~2.4** | **`yolo11n` показывает выдающуюся скорость инференса, сравнимую с `yolov8n`, и значительно превосходит более крупную `yolov8s`.** |\n",
    "| **FPS (полный пайплайн, оценка)** | ~385 FPS       | ~84 FPS         | **~416 FPS** | `yolo11n` является самой быстрой моделью в полном пайплайне, что делает ее наиболее предпочтительной для приложений реального времени.                                                                                                                                                                                                                                                                                                                              |\n",
    "\n",
    "### Окончательные выводы по выбору модели и дальнейшим экспериментам:\n",
    "\n",
    "На основании проведенного всестороннего сравнительного анализа трех моделей YOLO, можно сделать следующие ключевые выводы:\n",
    "\n",
    "1.  **YOLO11n - безоговорочный лидер для данной задачи:** Модель `yolo11n` демонстрирует **наилучший компромисс между высокой точностью и исключительной производительностью**. Она не только превосходит `yolov8n` и `yolov8s` по ключевым метрикам точности (особенно `mAP50-95`), но при этом является самой компактной, обучается быстрее всех и обеспечивает наивысший FPS в реальном времени. Ее способность обнаруживать все объекты (`Recall = 1.000`) при отличной точности локализации делает её идеальным выбором для надежной системы отслеживания сноубордистов.\n",
    "\n",
    "2.  **Подтверждение избыточности крупных моделей:** Результаты экспериментов с `yolov8s` ясно показывают, что увеличение сложности модели (от `n` к `s`) не приносит существенного прироста точности на нашем специфическом датасете, а ведет к значительному увеличению вычислительных затрат и снижению скорости. Это подтверждает, что для данной задачи и размера данных, более крупные версии YOLO (например, `yolov8m`, `yolov8l`, `yolov8x`) **не являются целесообразными и лишь приведут к неэффективному использованию ресурсов**.\n",
    "\n",
    "### Стоит ли пробовать YOLO12n?\n",
    "\n",
    "Ваш вопрос о `yolo12n` закономерен. Учитывая, как хорошо `yolo11n` показала себя, есть несколько соображений:\n",
    "\n",
    "* **Потенциал:** Каждая новая версия YOLO стремится к улучшению. `yolo12n` может предложить дальнейшие оптимизации архитектуры или тренировки, которые теоретически могли бы привести к небольшому, но заметному приросту точности при сохранении высокой скорости.\n",
    "* **Закон убывающей отдачи:** С другой стороны, мы уже достигли очень высоких метрик. `mAP50-95 = 0.859` и `Recall = 1.000` — это выдающиеся результаты. Прирост от `yolo12n`, если он и будет, скорее всего, окажется минимальным (доли процента), а время, затраченное на обучение и оценку новой модели, может не окупиться этим незначительным улучшением.\n",
    "* **Фокус проекта:** Если текущая цель — создать рабочую систему отслеживания, `yolo11n` уже более чем готова к интеграции. Время, которое вы потратите на дальнейшие бенчмаркинг моделей, можно было бы инвестировать в реализацию и оптимизацию самого алгоритма отслеживания.\n",
    "\n",
    "**Рекомендация:** На данном этапе, если `yolo11n` полностью удовлетворяет вашим требованиям по точности и скорости, **нет острой необходимости немедленно переходить к `yolo12n`**. Если в процессе интеграции в систему отслеживания или при работе с более сложными сценариями обнаружатся недостатки `yolo11n`, тогда можно вернуться к идее попробовать `yolo12n` или другие дальнейшие оптимизации (например, увеличение `imgsz` для `yolo11n` или дополнительное дообучение).\n",
    "\n",
    "**Итог:** Вы получили исключительную модель-детектор в лице `yolo11n`. Это отличный результат для перехода к следующей фазе проекта!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
